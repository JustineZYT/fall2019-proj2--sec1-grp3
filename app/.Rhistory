mutate(song = reorder(song, n)) %>%
ggplot(aes(song, n, fill = sentiment)) +
geom_col() +
coord_flip() +
labs(y = "Contribution to sentiment")
############################################
hiphop_song_counts <- tidy_hiphop %>%
inner_join(bing) %>%
count(artist, sentiment, sort = TRUE)
hiphop_song_counts %>%
filter(n >2000) %>%
mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
mutate(artist = reorder(artist, n)) %>%
ggplot(aes(artist, n%/%100, fill = sentiment)) +
geom_col() +
coord_flip() +
labs(y = "Contribution to sentiment")
hiphop_artists <- c('flo-rida', 'big-daddy-kane', 'chris-brown','black-eyed-peas','de-la-soul','childish-gambino', 'chamillionaire','dj-khaled','fat-joe', 'ghostface-killah','atmosphere','future','e-40','dr-dre','busta-rhymes','cypress-hill','dmx','bone-thugs-n-harmony','big-tymers','dj-quik','geto-boys','funkmaster-flex','canibus', 'epmd', 'd-12', 'eminem' )
tidy_hiphop_words <- c()
for (i in 1:length(hiphop_artists)){
uniq_words <- tidy_hiphop %>% filter(artist == hiphop_artists[i]) %>% count(word, sort=TRUE) %>% dim()
tidy_hiphop_words[i] <- uniq_words[1]
}
library(plotly)
p <- plot_ly(
x = hiphop_artists,
y = tidy_hiphop_words,
type = "bar"
) %>%
layout(
title="Hip-Hop Artist Vocabulary Size",
yaxis= list(
title="# of unique words in discography"
)
)
p
library(wordcloud)
par(mfrow=c(1,2), mar=c(3,1,3,1)-1)
cleaned_music <- tidy_eminem %>%
anti_join(get_stopwords())
em_cloud <- cleaned_music %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Spectral")))
###############
cleaned_hiphop <- tidy_hiphop %>%
anti_join(get_stopwords())
hip_cloud <- cleaned_hiphop %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Set2")))
library(reshape2)
par(mfrow=c(1,2), mar=c(3,3,3,1)-.2)
tidy_eminem %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
########
tidy_hiphop %>%
inner_join(bing) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
library("topicmodels")
emsongs <- filter(dt_lyrics, artist=='eminem')
em_onlysongs <- as.matrix(emsongs[,c('stemmedwords')])
docs <- Corpus(VectorSource(em_onlysongs))
dtm <- DocumentTermMatrix(docs)
rowTotals <- apply(dtm , 1, sum)
dtm  <- dtm[rowTotals> 0, ]
## run LDA for all inaugual speeches
burnin <- 4000
iter <- 1000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
# number of topics
k <- 5
# run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
ldaOut.topics <- as.matrix(topics(ldaOut))
ldaOut.terms <- as.matrix(terms(ldaOut,10))
ldaOut.terms
# probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
corpus.list <-  as.matrix(emsongs[,c('stemmedwords')])
topics.hash=c("Personal", "Love", "Rap", "Murder", "Rage")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]
colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
top10em <- as.matrix(topicProbabilities[c(50,193,194,195, 197, 199, 200, 202,203, 317, 428),c(1:5)])
rownames(top10em) <- c("MockingBird", "Stan", "When I'm Gone", "My Name Is", "Lose Yourself", "The Way I am", "Cleanin' Out My Closet", "Without Me", "The Real Slim Shady", "Till I Collapse", "Kill You")
heatmap(as.matrix(top10em), margins = c(8, 4))
hiphop_sentiment <- tidy_hiphop %>%
inner_join(bing) %>%
count(genre, index = ind%/% 450, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
library(tidytext)
library(tidyr)
library(ggplot2)
library(cowplot)
tidy_eminem <- filter(dt_lyrics, artist == 'eminem') %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_eminem <- cbind(tidy_eminem, "ind"= 1:dim(tidy_eminem)[1])
eminiem_sentiment <- tidy_eminem %>%
inner_join(bing) %>%
count(artist, index = ind%/% 1000, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
em_sentimentplot <- ggplot(eminiem_sentiment, aes(index, sentiment, fill = artist)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~artist, ncol = 2, scales = "free_x")+ ylim(-100, 100)
###########
tidy_hiphop <- filter(dt_lyrics, genre == 'Hip-Hop', year > 1999) %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_hiphop <- cbind(tidy_hiphop, "ind"= 1:dim(tidy_hiphop)[1])
hiphop_sentiment <- tidy_hiphop %>%
inner_join(bing) %>%
count(genre, index = ind%/% 450, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
hiphop_sentimentplot <- ggplot(hiphop_sentiment, aes(index, sentiment, fill = genre)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~genre, ncol = 2, scales = "free_x") + ylim(-100, 100)
plot_grid(em_sentimentplot, hiphop_sentimentplot)
library(tidytext)
library(tidyr)
library(ggplot2)
library(cowplot)
tidy_eminem <- filter(dt_lyrics, artist == 'eminem') %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_eminem <- cbind(tidy_eminem, "ind"= 1:dim(tidy_eminem)[1])
eminiem_sentiment <- tidy_eminem %>%
inner_join(bing) %>%
count(artist, index = ind%/% 1000, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
em_sentimentplot <- ggplot(eminiem_sentiment, aes(index, sentiment, fill = artist)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~artist, ncol = 2, scales = "free_x")+ ylim(-100, 100)
###########
tidy_hiphop <- filter(dt_lyrics, genre == 'Hip-Hop', year > 1999) %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_hiphop <- cbind(tidy_hiphop, "ind"= 1:dim(tidy_hiphop)[1])
hiphop_sentiment <- tidy_hiphop %>%
inner_join(bing) %>%
count(genre, index = ind%/% 300, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
hiphop_sentimentplot <- ggplot(hiphop_sentiment, aes(index, sentiment, fill = genre)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~genre, ncol = 2, scales = "free_x") + ylim(-100, 100)
plot_grid(em_sentimentplot, hiphop_sentimentplot)
library(tidytext)
library(tidyr)
library(ggplot2)
library(cowplot)
tidy_eminem <- filter(dt_lyrics, artist == 'eminem') %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_eminem <- cbind(tidy_eminem, "ind"= 1:dim(tidy_eminem)[1])
eminiem_sentiment <- tidy_eminem %>%
inner_join(bing) %>%
count(artist, index = ind%/% 900, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
em_sentimentplot <- ggplot(eminiem_sentiment, aes(index, sentiment, fill = artist)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~artist, ncol = 2, scales = "free_x")+ ylim(-100, 100)
###########
tidy_hiphop <- filter(dt_lyrics, genre == 'Hip-Hop', year > 1999) %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_hiphop <- cbind(tidy_hiphop, "ind"= 1:dim(tidy_hiphop)[1])
hiphop_sentiment <- tidy_hiphop %>%
inner_join(bing) %>%
count(genre, index = ind%/% 500, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
hiphop_sentimentplot <- ggplot(hiphop_sentiment, aes(index, sentiment, fill = genre)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~genre, ncol = 2, scales = "free_x") + ylim(-100, 100)
plot_grid(em_sentimentplot, hiphop_sentimentplot)
library(tidytext)
library(tidyr)
library(ggplot2)
library(cowplot)
tidy_eminem <- filter(dt_lyrics, artist == 'eminem') %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_eminem <- cbind(tidy_eminem, "ind"= 1:dim(tidy_eminem)[1])
eminiem_sentiment <- tidy_eminem %>%
inner_join(bing) %>%
count(artist, index = ind%/% 800, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
em_sentimentplot <- ggplot(eminiem_sentiment, aes(index, sentiment, fill = artist)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~artist, ncol = 2, scales = "free_x")+ ylim(-100, 100)
###########
tidy_hiphop <- filter(dt_lyrics, genre == 'Hip-Hop', year > 1999) %>%
unnest_tokens(word, lyrics)
bing <- get_sentiments("bing")
tidy_hiphop <- cbind(tidy_hiphop, "ind"= 1:dim(tidy_hiphop)[1])
hiphop_sentiment <- tidy_hiphop %>%
inner_join(bing) %>%
count(genre, index = ind%/% 500, sentiment) %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment = positive - negative)
hiphop_sentimentplot <- ggplot(hiphop_sentiment, aes(index, sentiment, fill = genre)) +
geom_bar(stat = "identity", show.legend = FALSE) +
facet_wrap(~genre, ncol = 2, scales = "free_x") + ylim(-100, 100)
plot_grid(em_sentimentplot, hiphop_sentimentplot)
library(wordcloud)
par(mfrow=c(1,2), mar=c(3,1,3,1)-1)
cleaned_music <- tidy_eminem %>%
anti_join(get_stopwords())
em_cloud <- cleaned_music %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Spectral")))
###############
cleaned_hiphop <- tidy_hiphop %>%
anti_join(get_stopwords())
hip_cloud <- cleaned_hiphop %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Set2")))
library(wordcloud)
par(mfrow=c(1,2), mar=c(3,1,3,1)-1)
cleaned_music <- tidy_eminem %>%
anti_join(get_stopwords())
em_cloud <- cleaned_music %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Spectral"), title='Eminems World Cloud'))
###############
cleaned_hiphop <- tidy_hiphop %>%
anti_join(get_stopwords())
hip_cloud <- cleaned_hiphop %>%
count(word) %>%
with(wordcloud(word, n, max.words = 100, random.order=FALSE, colors=brewer.pal(8, "Set2"), title='Hip-Hops Word Cloud'))
hhsongs <- filter(dt_lyrics, genre=='Hip-Hop')
hhsongs <- as.matrix(hhsongs[,c('stemmedwords')])
hdocs <- Corpus(VectorSource(hhsongs))
dtmh <- DocumentTermMatrix(hdocs)
rowTotals <- apply(dtmh , 1, sum)
hhsongs <- filter(dt_lyrics, genre=='Hip-Hop', year > 1999)
hhsongs <- as.matrix(hhsongs[,c('stemmedwords')])
hdocs <- Corpus(VectorSource(hhsongs))
dtmh <- DocumentTermMatrix(hdocs)
rowTotals <- apply(dtmh , 1, sum)
hhsongs <- filter(dt_lyrics, genre=='Hip-Hop', year > 1999)
hhsongs <- as.matrix(hhsongs[,c('stemmedwords')])
hdocs <- Corpus(VectorSource(hhsongs))
dtmh <- DocumentTermMatrix(hdocs)
rowTotals <- apply(dtmh , 1, sum)
# probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
corpus.list <-  as.matrix(emsongs[,c('stemmedwords')])
topics.hash=c("Personal", "Love", "Rap", "Murder", "Rage")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]
colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
top10em <- as.matrix(topicProbabilities[c(50,193,194,195, 197, 199, 200, 202,203, 317, 428),c(1:5)])
rownames(top10em) <- c("MockingBird", "Stan", "When I'm Gone", "My Name Is", "Lose Yourself", "The Way I am", "Cleanin' Out My Closet", "Without Me", "The Real Slim Shady", "Till I Collapse", "Kill You")
heatmap(as.matrix(top10em), margins = c(8, 4))
install.packages("shiny")
library(shiny)
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.path='figs/',
echo=T, warning=FALSE, message=FALSE)
if (!require("DT")) install.packages('DT')
if (!require("dtplyr")) install.packages('dtplyr')
if (!require("lubridate")) install.packages('lubridate')
if (!require("ggmap")) install.packages('ggmap')
if (!require("choroplethrZip")) {
# install.packages("devtools")
library(devtools)
install_github('arilamstein/choroplethrZip@v1.5.0')}
library(dtplyr)
library(dplyr)
library(DT)
library(lubridate)
runApp(getwd())
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
install.packages("leaflet")
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
install.packages("maps")
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
MyData <- read.csv(file="../data/calendar.csv", header=TRUE, sep=",")
View(MyData)
View(MyData)
listdetails <- read.csv(file="../data/listings_detail.csv", header=TRUE, sep=",")
reviews <- read.csv(file="../data/reviews_detail.csv", header=TRUE, sep=",")
View(listdetails)
View(listdetails)
View(listdetails)
View(listdetails)
View(MyData)
View(MyData)
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
shiny::runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
shiny::runApp('GitHub/fall2019-proj2--sec1-grp3/app')
install.packages("leaflet.extras")
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
shiny::runApp('GitHub/fall2019-proj2--sec1-grp3/app')
h <- hash()
install.packages("hashFunction")
hash()
shiny::runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp()
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
library(RColorBrewer)
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
install.packages("leaflet.extras")
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
install.packages("shinythemes")
shiny::runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
runApp('GitHub/fall2019-proj2--sec1-grp3/app')
rest_data <- read.csv("../data/rest_data.csv")
setwd("~/GitHub/fall2019-proj2--sec1-grp3/app")
setwd("~/GitHub/fall2019-proj2--sec1-grp3/app")
rest_data <- read.csv("../data/rest_data.csv")
asdf <- rest_data %>% filter(Type == 'korean')
View(asdf)
View(asdf)
runApp()
runApp()
runApp()
runApp()
runApp()
View(asdf)
View(asdf)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
